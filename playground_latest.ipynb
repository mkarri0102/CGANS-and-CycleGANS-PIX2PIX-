{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e15f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Generator import Generator \n",
    "from Discriminator import Discriminator \n",
    "from DataLoader import load_data \n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43579cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_image_tensor(list_tensors):\n",
    "    for i, x in enumerate(list_tensors):\n",
    "        x = x.permute(1,2,0)\n",
    "        fig = plt.figure(figsize=(6, 20))\n",
    "        plt.imshow(x.cpu().detach().numpy())\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class Experiment():\n",
    "        def __init__(self,name=\"default\"):\n",
    "            config_data = read_file_in_dir('./', name + '.json')\n",
    "            self.ROOT_STATS_DIR = './experiment_data'\n",
    "            if config_data is None:\n",
    "                raise Exception(\"Configuration file doesn't exist: \", name)\n",
    "\n",
    "            self.__name = config_data['experiment_name']\n",
    "            self.__experiment_dir = os.path.join(self.ROOT_STATS_DIR, self.__name)\n",
    "            self.config_data = config_data\n",
    "            self.__epochs = config_data['num_epochs']\n",
    "            self.image_dir=config_data['image_dir']\n",
    "            self.label_dir=config_data['label_dir']\n",
    "            self.lambd=config_data['lambda']\n",
    "            \n",
    "            self.__current_epoch = 0\n",
    "            self.__training_losses_gen = []\n",
    "            self.__training_losses_disc = []\n",
    "            \n",
    "            self.G = Generator(3, 64, 3)\n",
    "            self.D = Discriminator(6)\n",
    "            self.G.cuda()\n",
    "            self.D.cuda()\n",
    "            \n",
    "            self.G_optimizer = torch.optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "            self.D_optimizer = torch.optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "            self.dataloading()\n",
    "            \n",
    "            self.__load_experiment()\n",
    "            \n",
    "        def __load_experiment(self):\n",
    "            os.makedirs(self.ROOT_STATS_DIR, exist_ok=True)\n",
    "\n",
    "            if os.path.exists(self.__experiment_dir):\n",
    "                self.__training_losses_gen = read_file_in_dir(self.__experiment_dir, 'training_losses_gen.txt')\n",
    "                #self.__val_losses_gen = read_file_in_dir(self.__experiment_dir, 'val_losses_gen.txt')\n",
    "                self.__training_losses_disc = read_file_in_dir(self.__experiment_dir, 'training_losses_disc.txt')\n",
    "                #self.__val_losses_disc = read_file_in_dir(self.__experiment_dir, 'val_losses_disc.txt')\n",
    "                self.__current_epoch = len(self.__training_losses_disc)\n",
    "                self.__epochs-=self.__current_epoch\n",
    "\n",
    "                state_dict = torch.load(os.path.join(self.__experiment_dir, 'latest_model.pt'))\n",
    "                self.G.load_state_dict(state_dict['generator'])\n",
    "                self.D.load_state_dict(state_dict['discriminator'])\n",
    "                self.G_optimizer.load_state_dict(state_dict['optimizer_gen'])\n",
    "                self.D_optimizer.load_state_dict(state_dict['optimizer_disc'])\n",
    "\n",
    "\n",
    "            else:\n",
    "                os.makedirs(self.__experiment_dir)\n",
    "            \n",
    "        \n",
    "        def dataloading(self):\n",
    "            \n",
    "            self.train_data = load_data(self.image_dir, self.label_dir, subfolder='train/')\n",
    "            self.train_data_loader = torch.utils.data.DataLoader(dataset=self.train_data, batch_size=2,shuffle=True)\n",
    "\n",
    "            self.val_data = load_data(self.image_dir, self.label_dir, subfolder='val/')\n",
    "            self.val_data_loader = torch.utils.data.DataLoader(dataset=self.val_data, batch_size=2,shuffle=True)\n",
    "            self.val_input, self.val_target = self.val_data_loader.__iter__().__next__()\n",
    "\n",
    "        def train(self):\n",
    "\n",
    "            BCE_loss = nn.BCELoss().cuda()\n",
    "            L1_loss = nn.L1Loss().cuda()\n",
    "\n",
    "            self.G_optimizer = torch.optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "            self.D_optimizer = torch.optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "            D_avg_losses = []\n",
    "            G_avg_losses = []\n",
    "\n",
    "\n",
    "            for epoch in range(self.__epochs):\n",
    "                print(self.__current_epoch)\n",
    "                D_losses = []\n",
    "                G_losses = []\n",
    "\n",
    "                # training\n",
    "                for i,(input, target) in enumerate(self.train_data_loader):\n",
    "\n",
    "                    # input & target image data\n",
    "                    x_ = input.cuda()\n",
    "                    y_ = target.cuda()\n",
    "                    #print(y_.shape)\n",
    "\n",
    "                    # Train discriminator with real data\n",
    "                    D_real_decision = self.D(x_, y_).squeeze()\n",
    "                    real_ = torch.ones(D_real_decision.size()).cuda()\n",
    "                    D_real_loss = BCE_loss(D_real_decision, real_)\n",
    "\n",
    "                    # Train discriminator with fake data\n",
    "                    gen_image = self.G(x_)\n",
    "                    D_fake_decision = self.D(x_, gen_image).squeeze()\n",
    "                    fake_ = torch.zeros(D_fake_decision.size()).cuda()\n",
    "                    D_fake_loss = BCE_loss(D_fake_decision, fake_)\n",
    "\n",
    "                    # Back propagation\n",
    "                    D_loss = (D_real_loss + D_fake_loss) * 0.5\n",
    "                    self.D.zero_grad()\n",
    "                    D_loss.backward()\n",
    "                    self.D_optimizer.step()\n",
    "\n",
    "                    # Train generator\n",
    "                    gen_image = self.G(x_)\n",
    "                    D_fake_decision = self.D(x_, gen_image).squeeze()\n",
    "                    G_fake_loss = BCE_loss(D_fake_decision, real_)\n",
    "\n",
    "                    # L1 loss\n",
    "                    l1_loss =self.lambd * L1_loss(gen_image, y_) #(lambda value=100)\n",
    "\n",
    "                    # Back propagation\n",
    "                    G_loss = G_fake_loss + l1_loss\n",
    "                    self.G.zero_grad()\n",
    "                    G_loss.backward()\n",
    "                    self.G_optimizer.step()\n",
    "\n",
    "                    # loss values\n",
    "                    D_losses.append(D_loss.item())\n",
    "                    G_losses.append(G_loss.item())\n",
    "\n",
    "                    if(i%20==0):\n",
    "                        print('Epoch [%d/%d], Step [%d/%d], D_loss: %.4f, G_loss: %.4f'\n",
    "                             % (epoch+1,self.__epochs, i+1, len(self.train_data_loader), D_loss.item(), G_loss.item()))\n",
    "               \n",
    "\n",
    "                D_avg_loss = torch.mean(torch.FloatTensor(D_losses))\n",
    "                G_avg_loss = torch.mean(torch.FloatTensor(G_losses))\n",
    "\n",
    "                # avg loss values for plot\n",
    "                D_avg_losses.append(D_avg_loss)\n",
    "                G_avg_losses.append(G_avg_loss)\n",
    "                \n",
    "                self.__record_stats(D_avg_loss.item(), 'disc')\n",
    "                self.__record_stats(G_avg_loss.item(),  'gen')\n",
    "                self.__save_model()\n",
    "\n",
    "                #Show result for test image\n",
    "                gen_image = self.G(self.val_input.cuda())\n",
    "                gen_image = gen_image.cpu()\n",
    "                print_image_tensor([self.val_input[0], gen_image[0],self.val_target[0]])\n",
    "                self.__current_epoch+=1\n",
    "\n",
    "\n",
    "        def __save_model(self, name = 'latest_model.pt'):\n",
    "            root_model_path = os.path.join(self.__experiment_dir, name)    \n",
    "            torch.save({\n",
    "                'generator': self.G.state_dict(),\n",
    "                'discriminator': self.D.state_dict(),\n",
    "                'optimizer_gen': self.G_optimizer.state_dict(),\n",
    "                'optimizer_disc': self.D_optimizer.state_dict(),\n",
    "                }, root_model_path)\n",
    "                                          \n",
    "\n",
    "\n",
    "        def __record_stats(self, train_loss, loss_type):            \n",
    "            if(loss_type == 'gen'):\n",
    "                self.__training_losses_gen.append(train_loss)\n",
    "                #self.__val_losses_gen.append(val_loss)\n",
    "\n",
    "                self.plot_stats(loss_type)\n",
    "\n",
    "\n",
    "                write_to_file_in_dir(self.__experiment_dir, 'training_losses_'+loss_type +'.txt', self.__training_losses_gen)\n",
    "\n",
    "                #write_to_file_in_dir(self.__experiment_dir, 'val_losses_'+loss_type+'.txt', self.__val_losses_gen)\n",
    "\n",
    "\n",
    "            elif(loss_type == 'disc'):\n",
    "                self.__training_losses_disc.append(train_loss)\n",
    "                #self.__val_losses_disc.append(val_loss)\n",
    "\n",
    "                self.plot_stats(loss_type)\n",
    "\n",
    "                write_to_file_in_dir(self.__experiment_dir, 'training_losses_'+loss_type +'.txt', self.__training_losses_disc)\n",
    "                #write_to_file_in_dir(self.__experiment_dir, 'val_losses_'+loss_type+'.txt', self.__val_losses_disc)\n",
    "\n",
    "\n",
    "        def __log(self, log_str, file_name=None):\n",
    "            print(log_str)\n",
    "            log_to_file_in_dir(self.__experiment_dir, 'all.log', log_str)\n",
    "            if file_name is not None:\n",
    "                log_to_file_in_dir(self.__experiment_dir, file_name, log_str)\n",
    "\n",
    "        def __log_epoch_stats(self, start_time):\n",
    "            time_elapsed = datetime.now() - start_time\n",
    "            time_to_completion = time_elapsed * (self.__epochs - self.__current_epoch - 1)\n",
    "            train_loss = self.__training_losses_gen[self.__current_epoch]\n",
    "            #val_loss = self.__val_losses_disc[self.__current_epoch]\n",
    "            summary_str = \"Epoch: {}, Train Loss: {} , Took {}, ETA: {}\\n\"\n",
    "            summary_str = summary_str.format(self.__current_epoch + 1, train_loss, str(time_elapsed),\n",
    "                                             str(time_to_completion))\n",
    "            self.__log(summary_str, 'epoch.log')\n",
    "            train_loss = self.__training_losses_disc[self.__current_epoch]\n",
    "            #val_loss = self.__val_losses_disc[self.__current_epoch]\n",
    "            summary_str = \"Epoch: {}, Train Loss: {} , Took {}, ETA: {}\\n\"\n",
    "            summary_str = summary_str.format(self.__current_epoch + 1, train_loss, str(time_elapsed),\n",
    "                                             str(time_to_completion))\n",
    "            self.__log(summary_str, 'epoch.log')\n",
    "\n",
    "        def plot_stats(self, loss_type):\n",
    "            e = self.__current_epoch+1\n",
    "            x_axis = np.arange(1, e + 1)\n",
    "            plt.figure()\n",
    "            if(loss_type == 'disc'):\n",
    "                plt.title('Discriminator Loss Plot')\n",
    "                training_loss = self.__training_losses_disc\n",
    "                #validation_loss = self.__val_losses_disc\n",
    "            elif(loss_type == 'gen'):\n",
    "                plt.title('Generator Loss Plot')\n",
    "                training_loss = self.__training_losses_gen\n",
    "                #validation_loss = self.__val_losses_gen\n",
    "            plt.plot(x_axis, training_loss, label=\"Training Loss\")\n",
    "            #plt.plot(x_axis, validation_loss, label=\"Validation Loss\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94a2a9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Epoch [1/7], Step [1/98], D_loss: 0.9701, G_loss: 9.9632\n",
      "Epoch [1/7], Step [21/98], D_loss: 0.4450, G_loss: 11.6431\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6266/2572128317.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gen\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"disc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6266/801338757.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0;31m# loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     \u001b[0mD_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                     \u001b[0mG_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp=Experiment(\"default\")\n",
    "exp.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba24c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcbb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
